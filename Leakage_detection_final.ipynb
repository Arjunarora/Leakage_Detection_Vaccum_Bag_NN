{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewlZhtiflboC",
        "outputId": "f72f7c6b-c353-44f6-e2cb-1c5489dcf620"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.8/dist-packages (1.2.1)\n",
            "Requirement already satisfied: tensorflow>=2.0 in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (2.11.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (1.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (2.25.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (7.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (23.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (0.2.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (0.4.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.11.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.22.4)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.11.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.6.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (15.0.6.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.51.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (0.30.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.14.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (3.19.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (4.5.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (23.1.21)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (3.1.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.11.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (5.7.1)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.18.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (2.0.10)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (2022.12.7)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow>=2.0->keras-tuner) (0.38.4)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->keras-tuner) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (0.2.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (2.16.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (6.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (3.13.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "QOzc3Jq3llB0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import keras\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1UWdNywl1bL",
        "outputId": "d8cd1ee3-dbcc-49c2-9662-dff89c326bb1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the training dataset\n",
        "train_data = pd.read_csv('/content/drive/MyDrive/Leakage Detection/leakage_dataset_train_1000.csv')\n",
        "X_train = train_data.drop(['y1', 'y2'], axis=1).values\n",
        "Y_train = train_data[['y1', 'y2']].values\n",
        "\n",
        "# Adjust x4 values to correct for the malfunction\n",
        "X_train[:, 3] = X_train[:, 3] - np.mean(X_train[:, :3], axis=1)\n",
        "\n",
        "# Load the validation dataset\n",
        "val_data = pd.read_csv('/content/drive/MyDrive/Leakage Detection/leakage_dataset_validation_1000.csv')\n",
        "X_val = val_data.drop(['y1', 'y2'], axis=1).values\n",
        "Y_val = val_data[['y1', 'y2']].values"
      ],
      "metadata": {
        "id": "YpiVYk-ul8bt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a figure with subplots\n",
        "fig, axs = plt.subplots(2, 2, figsize=(8, 8))\n",
        "\n",
        "# Create box plots for each sensor\n",
        "axs[0, 0].boxplot(X_train[:, 0])\n",
        "axs[0, 0].set_title('Sensor x1')\n",
        "axs[0, 1].boxplot(X_train[:, 1])\n",
        "axs[0, 1].set_title('Sensor x2')\n",
        "axs[1, 0].boxplot(X_train[:, 2])\n",
        "axs[1, 0].set_title('Sensor x3')\n",
        "axs[1, 1].boxplot(X_train[:, 3])\n",
        "axs[1, 1].set_title('Sensor x4')\n",
        "\n",
        "# Set y-axis label\n",
        "fig.text(0.04, 0.5, 'Values', va='center', rotation='vertical')\n",
        "\n",
        "# Set title of the figure\n",
        "fig.suptitle('Distribution of Sensor Values in Training Data')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "PjxIszRrmEgS",
        "outputId": "7286ad51-c4d8-4d5d-86b4-de701437436e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)"
      ],
      "metadata": {
        "id": "aME3aRSQmI8K"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Define the hyperparameters\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "depth = 2\n",
        "width = 32\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Dense(width, input_dim=X_train.shape[1], activation='relu'))\n",
        "for i in range(depth - 1):\n",
        "    model.add(Dense(width, activation='relu'))\n",
        "model.add(Dense(2, activation='linear'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate)\n",
        "model.compile(loss='mean_absolute_error', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, Y_val))\n",
        "\n",
        "# Save the model\n",
        "model.save('/content/drive/MyDrive/Leakage Detection/Final_models/model_standard_0.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TD0K9KAmYvF",
        "outputId": "81135c85-412e-41a9-8175-e30afd15da27"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "32/32 [==============================] - 1s 11ms/step - loss: 0.3363 - accuracy: 0.7580 - val_loss: 0.3482 - val_accuracy: 0.7220\n",
            "Epoch 2/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1641 - accuracy: 0.8430 - val_loss: 0.3018 - val_accuracy: 0.8090\n",
            "Epoch 3/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0921 - accuracy: 0.9240 - val_loss: 0.3634 - val_accuracy: 0.8830\n",
            "Epoch 4/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0754 - accuracy: 0.9430 - val_loss: 0.3498 - val_accuracy: 0.8660\n",
            "Epoch 5/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0670 - accuracy: 0.9480 - val_loss: 0.3608 - val_accuracy: 0.8700\n",
            "Epoch 6/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0644 - accuracy: 0.9420 - val_loss: 0.3724 - val_accuracy: 0.8660\n",
            "Epoch 7/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0626 - accuracy: 0.9410 - val_loss: 0.3346 - val_accuracy: 0.8680\n",
            "Epoch 8/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0625 - accuracy: 0.9410 - val_loss: 0.3432 - val_accuracy: 0.8720\n",
            "Epoch 9/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0640 - accuracy: 0.9320 - val_loss: 0.3395 - val_accuracy: 0.8650\n",
            "Epoch 10/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0595 - accuracy: 0.9390 - val_loss: 0.3526 - val_accuracy: 0.8800\n",
            "Epoch 11/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0590 - accuracy: 0.9420 - val_loss: 0.3519 - val_accuracy: 0.8790\n",
            "Epoch 12/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0586 - accuracy: 0.9410 - val_loss: 0.3523 - val_accuracy: 0.8800\n",
            "Epoch 13/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0599 - accuracy: 0.9390 - val_loss: 0.3542 - val_accuracy: 0.8670\n",
            "Epoch 14/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0582 - accuracy: 0.9410 - val_loss: 0.3425 - val_accuracy: 0.8760\n",
            "Epoch 15/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0574 - accuracy: 0.9470 - val_loss: 0.3676 - val_accuracy: 0.8780\n",
            "Epoch 16/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0571 - accuracy: 0.9430 - val_loss: 0.3423 - val_accuracy: 0.8840\n",
            "Epoch 17/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0553 - accuracy: 0.9380 - val_loss: 0.3510 - val_accuracy: 0.8800\n",
            "Epoch 18/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0560 - accuracy: 0.9440 - val_loss: 0.3592 - val_accuracy: 0.8670\n",
            "Epoch 19/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0553 - accuracy: 0.9380 - val_loss: 0.3562 - val_accuracy: 0.8690\n",
            "Epoch 20/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0555 - accuracy: 0.9440 - val_loss: 0.3477 - val_accuracy: 0.8790\n",
            "Epoch 21/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0548 - accuracy: 0.9340 - val_loss: 0.3493 - val_accuracy: 0.8690\n",
            "Epoch 22/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0534 - accuracy: 0.9440 - val_loss: 0.3532 - val_accuracy: 0.8650\n",
            "Epoch 23/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0548 - accuracy: 0.9440 - val_loss: 0.3623 - val_accuracy: 0.8660\n",
            "Epoch 24/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0536 - accuracy: 0.9500 - val_loss: 0.3600 - val_accuracy: 0.8670\n",
            "Epoch 25/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0530 - accuracy: 0.9450 - val_loss: 0.3472 - val_accuracy: 0.8820\n",
            "Epoch 26/100\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.0547 - accuracy: 0.9440 - val_loss: 0.3600 - val_accuracy: 0.8650\n",
            "Epoch 27/100\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0529 - accuracy: 0.9480 - val_loss: 0.3475 - val_accuracy: 0.8710\n",
            "Epoch 28/100\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0531 - accuracy: 0.9460 - val_loss: 0.3513 - val_accuracy: 0.8700\n",
            "Epoch 29/100\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0519 - accuracy: 0.9400 - val_loss: 0.3702 - val_accuracy: 0.8650\n",
            "Epoch 30/100\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0526 - accuracy: 0.9470 - val_loss: 0.3494 - val_accuracy: 0.8830\n",
            "Epoch 31/100\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0536 - accuracy: 0.9430 - val_loss: 0.3500 - val_accuracy: 0.8650\n",
            "Epoch 32/100\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0524 - accuracy: 0.9460 - val_loss: 0.3608 - val_accuracy: 0.8680\n",
            "Epoch 33/100\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0529 - accuracy: 0.9440 - val_loss: 0.3467 - val_accuracy: 0.8690\n",
            "Epoch 34/100\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0518 - accuracy: 0.9470 - val_loss: 0.3405 - val_accuracy: 0.8690\n",
            "Epoch 35/100\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0529 - accuracy: 0.9460 - val_loss: 0.3480 - val_accuracy: 0.8730\n",
            "Epoch 36/100\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0542 - accuracy: 0.9530 - val_loss: 0.3595 - val_accuracy: 0.8740\n",
            "Epoch 37/100\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0521 - accuracy: 0.9450 - val_loss: 0.3555 - val_accuracy: 0.8770\n",
            "Epoch 38/100\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0512 - accuracy: 0.9510 - val_loss: 0.3344 - val_accuracy: 0.8760\n",
            "Epoch 39/100\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0537 - accuracy: 0.9500 - val_loss: 0.3679 - val_accuracy: 0.8770\n",
            "Epoch 40/100\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0528 - accuracy: 0.9450 - val_loss: 0.3447 - val_accuracy: 0.8610\n",
            "Epoch 41/100\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0522 - accuracy: 0.9500 - val_loss: 0.3580 - val_accuracy: 0.8730\n",
            "Epoch 42/100\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0508 - accuracy: 0.9500 - val_loss: 0.3531 - val_accuracy: 0.8690\n",
            "Epoch 43/100\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0511 - accuracy: 0.9440 - val_loss: 0.3514 - val_accuracy: 0.8740\n",
            "Epoch 44/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0511 - accuracy: 0.9530 - val_loss: 0.3462 - val_accuracy: 0.8690\n",
            "Epoch 45/100\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0516 - accuracy: 0.9480 - val_loss: 0.3596 - val_accuracy: 0.8850\n",
            "Epoch 46/100\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0500 - accuracy: 0.9470 - val_loss: 0.3513 - val_accuracy: 0.8670\n",
            "Epoch 47/100\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0508 - accuracy: 0.9510 - val_loss: 0.3605 - val_accuracy: 0.8780\n",
            "Epoch 48/100\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0504 - accuracy: 0.9500 - val_loss: 0.3290 - val_accuracy: 0.8800\n",
            "Epoch 49/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0513 - accuracy: 0.9470 - val_loss: 0.3477 - val_accuracy: 0.8760\n",
            "Epoch 50/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0505 - accuracy: 0.9490 - val_loss: 0.3480 - val_accuracy: 0.8710\n",
            "Epoch 51/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0498 - accuracy: 0.9470 - val_loss: 0.3463 - val_accuracy: 0.8840\n",
            "Epoch 52/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0494 - accuracy: 0.9550 - val_loss: 0.3561 - val_accuracy: 0.8640\n",
            "Epoch 53/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0497 - accuracy: 0.9520 - val_loss: 0.3611 - val_accuracy: 0.8830\n",
            "Epoch 54/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0507 - accuracy: 0.9530 - val_loss: 0.3472 - val_accuracy: 0.8700\n",
            "Epoch 55/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0516 - accuracy: 0.9440 - val_loss: 0.3610 - val_accuracy: 0.8690\n",
            "Epoch 56/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0503 - accuracy: 0.9440 - val_loss: 0.3383 - val_accuracy: 0.8720\n",
            "Epoch 57/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0496 - accuracy: 0.9470 - val_loss: 0.3467 - val_accuracy: 0.8770\n",
            "Epoch 58/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0503 - accuracy: 0.9440 - val_loss: 0.3517 - val_accuracy: 0.8620\n",
            "Epoch 59/100\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0497 - accuracy: 0.9400 - val_loss: 0.3473 - val_accuracy: 0.8760\n",
            "Epoch 60/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0501 - accuracy: 0.9520 - val_loss: 0.3405 - val_accuracy: 0.8810\n",
            "Epoch 61/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0502 - accuracy: 0.9480 - val_loss: 0.3622 - val_accuracy: 0.8760\n",
            "Epoch 62/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0514 - accuracy: 0.9480 - val_loss: 0.3380 - val_accuracy: 0.8730\n",
            "Epoch 63/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0507 - accuracy: 0.9480 - val_loss: 0.3564 - val_accuracy: 0.8880\n",
            "Epoch 64/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0510 - accuracy: 0.9440 - val_loss: 0.3361 - val_accuracy: 0.8810\n",
            "Epoch 65/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0504 - accuracy: 0.9420 - val_loss: 0.3540 - val_accuracy: 0.8660\n",
            "Epoch 66/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0505 - accuracy: 0.9430 - val_loss: 0.3503 - val_accuracy: 0.8810\n",
            "Epoch 67/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0493 - accuracy: 0.9370 - val_loss: 0.3658 - val_accuracy: 0.8750\n",
            "Epoch 68/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0508 - accuracy: 0.9460 - val_loss: 0.3574 - val_accuracy: 0.8660\n",
            "Epoch 69/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0491 - accuracy: 0.9460 - val_loss: 0.3516 - val_accuracy: 0.8720\n",
            "Epoch 70/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0498 - accuracy: 0.9470 - val_loss: 0.3397 - val_accuracy: 0.8810\n",
            "Epoch 71/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0501 - accuracy: 0.9450 - val_loss: 0.3328 - val_accuracy: 0.8760\n",
            "Epoch 72/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0493 - accuracy: 0.9500 - val_loss: 0.3580 - val_accuracy: 0.8660\n",
            "Epoch 73/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0493 - accuracy: 0.9460 - val_loss: 0.3511 - val_accuracy: 0.8740\n",
            "Epoch 74/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0489 - accuracy: 0.9510 - val_loss: 0.3558 - val_accuracy: 0.8630\n",
            "Epoch 75/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0497 - accuracy: 0.9410 - val_loss: 0.3473 - val_accuracy: 0.8840\n",
            "Epoch 76/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0495 - accuracy: 0.9480 - val_loss: 0.3502 - val_accuracy: 0.8770\n",
            "Epoch 77/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0485 - accuracy: 0.9490 - val_loss: 0.3503 - val_accuracy: 0.8780\n",
            "Epoch 78/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0482 - accuracy: 0.9510 - val_loss: 0.3608 - val_accuracy: 0.8770\n",
            "Epoch 79/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0493 - accuracy: 0.9470 - val_loss: 0.3479 - val_accuracy: 0.8630\n",
            "Epoch 80/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0497 - accuracy: 0.9480 - val_loss: 0.3529 - val_accuracy: 0.8750\n",
            "Epoch 81/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0486 - accuracy: 0.9510 - val_loss: 0.3535 - val_accuracy: 0.8820\n",
            "Epoch 82/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0488 - accuracy: 0.9510 - val_loss: 0.3393 - val_accuracy: 0.8760\n",
            "Epoch 83/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0489 - accuracy: 0.9490 - val_loss: 0.3397 - val_accuracy: 0.8760\n",
            "Epoch 84/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0495 - accuracy: 0.9510 - val_loss: 0.3458 - val_accuracy: 0.8710\n",
            "Epoch 85/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0485 - accuracy: 0.9500 - val_loss: 0.3512 - val_accuracy: 0.8710\n",
            "Epoch 86/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0473 - accuracy: 0.9490 - val_loss: 0.3473 - val_accuracy: 0.8800\n",
            "Epoch 87/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0478 - accuracy: 0.9520 - val_loss: 0.3562 - val_accuracy: 0.8620\n",
            "Epoch 88/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0500 - accuracy: 0.9470 - val_loss: 0.3500 - val_accuracy: 0.8740\n",
            "Epoch 89/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0482 - accuracy: 0.9450 - val_loss: 0.3568 - val_accuracy: 0.8860\n",
            "Epoch 90/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0480 - accuracy: 0.9490 - val_loss: 0.3617 - val_accuracy: 0.8770\n",
            "Epoch 91/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0503 - accuracy: 0.9460 - val_loss: 0.3427 - val_accuracy: 0.8900\n",
            "Epoch 92/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0482 - accuracy: 0.9480 - val_loss: 0.3453 - val_accuracy: 0.8660\n",
            "Epoch 93/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0500 - accuracy: 0.9480 - val_loss: 0.3528 - val_accuracy: 0.8760\n",
            "Epoch 94/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0483 - accuracy: 0.9540 - val_loss: 0.3485 - val_accuracy: 0.8800\n",
            "Epoch 95/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0483 - accuracy: 0.9470 - val_loss: 0.3641 - val_accuracy: 0.8730\n",
            "Epoch 96/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0488 - accuracy: 0.9470 - val_loss: 0.3426 - val_accuracy: 0.8970\n",
            "Epoch 97/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0476 - accuracy: 0.9520 - val_loss: 0.3490 - val_accuracy: 0.8690\n",
            "Epoch 98/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0488 - accuracy: 0.9450 - val_loss: 0.3411 - val_accuracy: 0.8960\n",
            "Epoch 99/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0483 - accuracy: 0.9470 - val_loss: 0.3486 - val_accuracy: 0.8760\n",
            "Epoch 100/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0479 - accuracy: 0.9480 - val_loss: 0.3521 - val_accuracy: 0.8940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model('/content/drive/MyDrive/Leakage Detection/Final_models/model_standard_0.h5')\n",
        "\n",
        "# Make predictions on new data\n",
        "X_new = [[1.51622149e+00, -5.42255062e-01, -6.40267721e-01,\n",
        "        -2.32916509e-01]]\n",
        "predictions = model.predict(X_new)\n",
        "\n",
        "\n",
        "y1_predictions = predictions[:,0]\n",
        "y2_predictions = predictions[:,1]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jW4FW_Rwmn7e",
        "outputId": "c51a9def-90fe-4da0-f2e3-175041bb73a2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 79ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y1_predictions, y2_predictions\n",
        "#Actual values [-0.71571846,  0.31258276]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjvXBj4zm1ye",
        "outputId": "b8fa10c0-1fc9-4ef3-8d25-3ccff4efe9e7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-0.67262894], dtype=float32), array([0.33399275], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VUrlflFHm65h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "Fy-d2u_Em9ch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kerastuner as kt\n",
        "\n",
        "# Define the search space for the hyperparameters\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(hp.Int('width', min_value=32, max_value=512, step=32), input_dim=X_train.shape[1], activation='relu'))\n",
        "    for i in range(hp.Int('depth', 1, 5) - 1):\n",
        "        model.add(Dense(hp.Int('width', min_value=32, max_value=512, step=32), activation='relu'))\n",
        "    model.add(Dense(2, activation='linear'))\n",
        "    model.compile(loss='mean_absolute_error',metrics=['accuracy'],optimizer=Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])))\n",
        "    return model\n",
        "\n",
        "# Create a tuner\n",
        "tuner = kt.Hyperband(build_model, objective='val_loss', max_epochs=100, factor=3, directory='my_dir', project_name='my_project')\n",
        "\n",
        "# Search for the best hyperparameters\n",
        "tuner.search(X_train, Y_train, validation_data=(X_val, Y_val))\n",
        "\n",
        "# Get the best model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Save the best model\n",
        "best_model.save('/content/drive/MyDrive/Leakage Detection/Final_models/model_standard_1.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lrTKMLYnAT5",
        "outputId": "f09a5f77-3ca2-40ad-b059-fd54da2a15d1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 254 Complete [00h 00m 23s]\n",
            "val_loss: 0.2464475929737091\n",
            "\n",
            "Best val_loss So Far: 0.17419447004795074\n",
            "Total elapsed time: 00h 25m 03s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model\n",
        "model = load_model('/content/drive/MyDrive/Leakage Detection/Final_models/model_standard_1.h5')\n",
        "\n",
        "# Make predictions on new data\n",
        "X_new = [[9.81493155e-01, -3.10622537e-01, -3.61754939e-01,\n",
        "        -2.30459658e-01]]\n",
        "predictions = model.predict(X_new)\n",
        "\n",
        "y1_predictions = predictions[:,0]\n",
        "y2_predictions = predictions[:,1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUT8te5NnIH6",
        "outputId": "c3be7f3f-26d5-4814-8c74-c6af439c45dc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 126ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y1_predictions, y2_predictions\n",
        "#Actual values  [-0.40606274,  0.29526814]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7Nijg85s8HB",
        "outputId": "c71769a3-fbe1-4532-f6ff-d962da3adcc7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-0.3299892], dtype=float32), array([0.43579534], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Augment the dataset. Each training example (x,y) can be comple- mented by seven additional virtual examples as illustrated in Figure 1. Clockwise rotations and flips on input data x are obtained as described above. A clockwise rotation on output data y is obtained through y90 = (y2,y1) and a flip along the vertical axis on the same data is represented by yflipped = (y1,y2). All other operations (rotation an- gles and associated flips) can be computed by subsequent application of these two operations.\n"
      ],
      "metadata": {
        "id": "npbymTmxtHfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def augment_data(X_train, Y_train):\n",
        "    # 90 degree rotation\n",
        "    X_train_rotated_90 = np.rot90(X_train, k=1, axes=(1,0))\n",
        "    Y_train_rotated_90 = np.fliplr(Y_train) * np.array([-1, 1])\n",
        "    print(X_train_rotated_90.shape,Y_train_rotated_90.shape)\n",
        "\n",
        "    # 180 degree rotation\n",
        "    X_train_rotated_180 = np.rot90(X_train, k=2, axes=(1,0))\n",
        "    Y_train_rotated_180 = Y_train * np.array([-1, -1])\n",
        "    print(X_train_rotated_180.shape,Y_train_rotated_180.shape)\n",
        "\n",
        "\n",
        "    # 270 degree rotation\n",
        "    X_train_rotated_270 = np.rot90(X_train, k=3, axes=(1,0))\n",
        "    Y_train_rotated_270 = np.fliplr(Y_train) * np.array([1, -1])\n",
        "    print(X_train_rotated_270.shape,Y_train_rotated_270.shape)\n",
        "\n",
        "    # flip\n",
        "    X_train_flipped = np.fliplr(X_train)\n",
        "    Y_train_flipped = Y_train * np.array([-1, 1])    \n",
        "    print(X_train_flipped.shape,Y_train_flipped.shape)\n",
        "\n",
        "    \n",
        "    # 90 degree rotation and flip\n",
        "    X_train_rotated_90_flipped = np.rot90(X_train_flipped, k=1, axes=(1,0))\n",
        "    Y_train_rotated_90_flipped = np.fliplr(Y_train_flipped) * np.array([-1, 1])\n",
        "    print(X_train_rotated_90_flipped.shape,Y_train_rotated_90_flipped.shape)\n",
        "\n",
        "    # 180 degree rotation and flip\n",
        "    X_train_rotated_180_flipped = np.rot90(X_train_flipped, k=2, axes=(1,0))\n",
        "    Y_train_rotated_180_flipped = Y_train_flipped * np.array([-1, -1])\n",
        "    print(X_train_rotated_180_flipped.shape,Y_train_rotated_180_flipped.shape)\n",
        "\n",
        "    # 270 degree rotation and flip\n",
        "    X_train_rotated_270_flipped = np.rot90(X_train_flipped, k=3, axes=(1,0))\n",
        "    Y_train_rotated_270_flipped = np.fliplr(Y_train_flipped) * np.array([1, -1])\n",
        "    print(X_train_rotated_270_flipped.shape,Y_train_rotated_270_flipped.shape)\n",
        "\n",
        "\n",
        "    X_augmented = np.concatenate((X_train, X_train_rotated_90.reshape(1000,4), X_train_rotated_180, X_train_rotated_270.reshape(1000,4), X_train_flipped,\n",
        "                                  X_train_rotated_90_flipped.reshape(1000,4), X_train_rotated_180_flipped, X_train_rotated_270_flipped.reshape(1000,4)), axis=0)\n",
        "    Y_augmented = np.concatenate((Y_train, Y_train_rotated_90, Y_train_rotated_180, Y_train_rotated_270, Y_train_flipped,\n",
        "                                  Y_train_rotated_90_flipped, Y_train_rotated_180_flipped, Y_train_rotated_270_flipped), axis=0)\n",
        "    return X_augmented, Y_augmented\n"
      ],
      "metadata": {
        "id": "agi-xLQttFC3"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_augmented, Y_train_augmented = augment_data(X_train, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAYQlbm6tJ3H",
        "outputId": "8a5343fc-02f2-4894-9816-29a97a396e21"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 1000) (1000, 2)\n",
            "(1000, 4) (1000, 2)\n",
            "(4, 1000) (1000, 2)\n",
            "(1000, 4) (1000, 2)\n",
            "(4, 1000) (1000, 2)\n",
            "(1000, 4) (1000, 2)\n",
            "(4, 1000) (1000, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the search space for the hyperparameters\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(hp.Int('width', min_value=32, max_value=512, step=32), input_dim=X_train.shape[1], activation='relu'))\n",
        "    for i in range(hp.Int('depth', 1, 5) - 1):\n",
        "        model.add(Dense(hp.Int('width', min_value=32, max_value=512, step=32), activation='relu'))\n",
        "    model.add(Dense(2, activation='linear'))\n",
        "    model.compile(loss='mean_absolute_error',metrics = ['accuracy'], optimizer=Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])))\n",
        "    return model\n",
        "\n",
        "# Create a tuner\n",
        "tuner = kt.Hyperband(build_model, objective='val_loss', max_epochs=100, factor=3, directory='my_dir_2', project_name='my_project')\n",
        "\n",
        "# Search for the best hyperparameters\n",
        "tuner.search(X_train_augmented, Y_train_augmented, validation_data=(X_val, Y_val))\n",
        "\n",
        "# Get the best model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Save the best model\n",
        "best_model.save('/content/drive/MyDrive/Leakage Detection/Final_models/model_standard_2.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBXF8MaGtLXu",
        "outputId": "8ffcf7e4-8daa-4938-e538-82fd5cd1e6d5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 254 Complete [00h 01m 23s]\n",
            "val_loss: 0.43796664476394653\n",
            "\n",
            "Best val_loss So Far: 0.2976060211658478\n",
            "Total elapsed time: 01h 24m 16s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model\n",
        "model = load_model('/content/drive/MyDrive/Leakage Detection/Final_models/model_standard_2.h5')\n",
        "\n",
        "# Make predictions on new data\n",
        "X_new = [[9.81493155e-01, -3.10622537e-01, -3.61754939e-01,\n",
        "        -2.30459658e-01]]\n",
        "predictions = model.predict(X_new)\n",
        "y1_predictions = predictions[:,0]\n",
        "y2_predictions = predictions[:,1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8g-XY0ZXtbsi",
        "outputId": "a1375bb3-0402-4457-bfc3-cfc3c430a9a5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f451e2f84c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 134ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y1_predictions, y2_predictions\n",
        "#Actual values  [-0.40606274,  0.29526814]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3C0LJqbg0VZo",
        "outputId": "e7d3fcc6-214b-4720-9b62-6925256e27b1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-0.03584344], dtype=float32), array([-0.02380597], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EquivariantHiddenLayer(keras.layers.Layer):\n",
        "  def _init_(self,name =None,**kwargs):\n",
        "    super(EquivariantHiddenLayer, self)._init_(**kwargs)\n",
        "    \n",
        "  def build(self, input_shape):\n",
        "    initializer = tf.keras.initializers.RandomNormal(stddev=0.2)\n",
        "    self.a = self.add_weight(name='w1',shape = (), initializer = initializer, trainable = True)\n",
        "    self.b = self.add_weight(name='w2',shape = (), initializer = initializer, trainable = True)\n",
        "    self.c = self.add_weight(name='w3',shape = (), initializer = initializer, trainable = True)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    W1 = [[self.a, self.b, self.c, self.b],\n",
        "          [self.b, self.a, self.b, self.c],\n",
        "          [self.c, self.b, self.a, self.b],\n",
        "          [self.b, self.c, self.b, self.a]]\n",
        "    return tf.matmul(inputs, W1)\n",
        "\t\n",
        " \n",
        "class EquivariantOutputLayer(keras.layers.Layer):\n",
        "  def _init_(self, **kwargs):\n",
        "    super(EquivariantOutputLayer, self)._init_(**kwargs)\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    initializer = tf.keras.initializers.RandomNormal(stddev=0.2)\n",
        "    self.d = self.add_weight(name = \"o1\", shape = (), initializer = initializer, trainable = True)\n",
        "        \n",
        "  def call(self, inputs):\n",
        "    first_term = self.d * tf.reduce_sum(inputs * [1, -1, -1, 1], axis=1, keepdims=True)\n",
        "    second_term = self.d * tf.reduce_sum(inputs * [-1, -1, 1, 1], axis=1, keepdims=True)\n",
        "    return tf.concat([first_term, second_term], axis=1)"
      ],
      "metadata": {
        "id": "yMzHSS7K0XGV"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the hyperparameters\n",
        "epochs = 50\n",
        "batch_size = 32\n",
        "learning_rate = 0.01\n",
        "depth = 2\n",
        "width = 32\n",
        " \n",
        "#Defining the Model \n",
        "model_equivariant_100 = tf.keras.Sequential()\n",
        "model_equivariant_100.add(EquivariantHiddenLayer())\n",
        "model_equivariant_100.add(EquivariantOutputLayer())\n",
        "model_equivariant_100.compile(optimizer = Adam(0.01), loss='mean_absolute_error', metrics = [\"accuracy\"])\n",
        "# Train the model\n",
        "history = model_equivariant_100.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, Y_val))\n",
        "\n",
        "# Save the model\n",
        "model.save('/content/drive/MyDrive/Leakage Detection/Final_models/model_equivariant_3.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUr1HWXq0fzL",
        "outputId": "7aa6acda-632d-4907-9c0e-a23a2555c767"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 2s 14ms/step - loss: 0.3745 - accuracy: 0.9270 - val_loss: 0.2629 - val_accuracy: 0.9490\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9440 - val_loss: 0.2531 - val_accuracy: 0.9490\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1125 - accuracy: 0.9440 - val_loss: 0.2643 - val_accuracy: 0.9490\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1131 - accuracy: 0.9440 - val_loss: 0.2650 - val_accuracy: 0.9490\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1129 - accuracy: 0.9440 - val_loss: 0.2589 - val_accuracy: 0.9490\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1125 - accuracy: 0.9440 - val_loss: 0.2581 - val_accuracy: 0.9490\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1117 - accuracy: 0.9440 - val_loss: 0.2569 - val_accuracy: 0.9490\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1116 - accuracy: 0.9440 - val_loss: 0.2500 - val_accuracy: 0.9490\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1125 - accuracy: 0.9440 - val_loss: 0.2651 - val_accuracy: 0.9490\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1118 - accuracy: 0.9440 - val_loss: 0.2559 - val_accuracy: 0.9490\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1122 - accuracy: 0.9440 - val_loss: 0.2559 - val_accuracy: 0.9490\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1120 - accuracy: 0.9440 - val_loss: 0.2629 - val_accuracy: 0.9490\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1125 - accuracy: 0.9440 - val_loss: 0.2515 - val_accuracy: 0.9490\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1121 - accuracy: 0.9440 - val_loss: 0.2653 - val_accuracy: 0.9490\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1122 - accuracy: 0.9440 - val_loss: 0.2558 - val_accuracy: 0.9490\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1117 - accuracy: 0.9440 - val_loss: 0.2611 - val_accuracy: 0.9490\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1117 - accuracy: 0.9440 - val_loss: 0.2541 - val_accuracy: 0.9490\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1119 - accuracy: 0.9440 - val_loss: 0.2652 - val_accuracy: 0.9490\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1120 - accuracy: 0.9440 - val_loss: 0.2587 - val_accuracy: 0.9490\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1123 - accuracy: 0.9440 - val_loss: 0.2722 - val_accuracy: 0.9490\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1121 - accuracy: 0.9440 - val_loss: 0.2468 - val_accuracy: 0.9490\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1133 - accuracy: 0.9440 - val_loss: 0.2559 - val_accuracy: 0.9490\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1120 - accuracy: 0.9440 - val_loss: 0.2459 - val_accuracy: 0.9490\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1126 - accuracy: 0.9440 - val_loss: 0.2471 - val_accuracy: 0.9490\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1116 - accuracy: 0.9440 - val_loss: 0.2506 - val_accuracy: 0.9490\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1134 - accuracy: 0.9440 - val_loss: 0.2723 - val_accuracy: 0.9490\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1122 - accuracy: 0.9440 - val_loss: 0.2599 - val_accuracy: 0.9490\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1122 - accuracy: 0.9440 - val_loss: 0.2545 - val_accuracy: 0.9490\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1120 - accuracy: 0.9440 - val_loss: 0.2681 - val_accuracy: 0.9490\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1130 - accuracy: 0.9440 - val_loss: 0.2523 - val_accuracy: 0.9490\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1122 - accuracy: 0.9440 - val_loss: 0.2515 - val_accuracy: 0.9490\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1122 - accuracy: 0.9440 - val_loss: 0.2687 - val_accuracy: 0.9490\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1128 - accuracy: 0.9440 - val_loss: 0.2599 - val_accuracy: 0.9490\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1127 - accuracy: 0.9440 - val_loss: 0.2507 - val_accuracy: 0.9490\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1120 - accuracy: 0.9440 - val_loss: 0.2501 - val_accuracy: 0.9490\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1118 - accuracy: 0.9440 - val_loss: 0.2556 - val_accuracy: 0.9490\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1123 - accuracy: 0.9440 - val_loss: 0.2626 - val_accuracy: 0.9490\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1127 - accuracy: 0.9440 - val_loss: 0.2791 - val_accuracy: 0.9490\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1136 - accuracy: 0.9440 - val_loss: 0.2526 - val_accuracy: 0.9490\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1122 - accuracy: 0.9440 - val_loss: 0.2564 - val_accuracy: 0.9490\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1124 - accuracy: 0.9440 - val_loss: 0.2514 - val_accuracy: 0.9490\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1118 - accuracy: 0.9440 - val_loss: 0.2513 - val_accuracy: 0.9490\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1122 - accuracy: 0.9440 - val_loss: 0.2638 - val_accuracy: 0.9490\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1120 - accuracy: 0.9440 - val_loss: 0.2585 - val_accuracy: 0.9490\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1116 - accuracy: 0.9440 - val_loss: 0.2643 - val_accuracy: 0.9490\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1133 - accuracy: 0.9440 - val_loss: 0.2585 - val_accuracy: 0.9490\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1129 - accuracy: 0.9440 - val_loss: 0.2697 - val_accuracy: 0.9490\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.1125 - accuracy: 0.9440 - val_loss: 0.2474 - val_accuracy: 0.9490\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.1128 - accuracy: 0.9440 - val_loss: 0.2618 - val_accuracy: 0.9490\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1124 - accuracy: 0.9440 - val_loss: 0.2584 - val_accuracy: 0.9490\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model for Augmented Dataset\n",
        "history = model_equivariant_100.fit(X_train_augmented, Y_train_augmented, batch_size=batch_size, epochs=epochs, validation_data=(X_val, Y_val))\n",
        "\n",
        "# Save the model\n",
        "model.save('/content/drive/MyDrive/Leakage Detection/Final_models/model_equivariant_4_augmented.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egX8y-mS0heF",
        "outputId": "23b948df-1b2d-44f0-9aa6-5715827a8ba0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.5091 - accuracy: 0.5067 - val_loss: 0.4882 - val_accuracy: 0.9490\n",
            "Epoch 2/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.5067 - val_loss: 0.4905 - val_accuracy: 0.9490\n",
            "Epoch 3/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.5052 - accuracy: 0.5067 - val_loss: 0.4922 - val_accuracy: 0.9490\n",
            "Epoch 4/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.5067 - val_loss: 0.4958 - val_accuracy: 0.9490\n",
            "Epoch 5/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.5067 - val_loss: 0.4976 - val_accuracy: 0.9490\n",
            "Epoch 6/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.5067 - val_loss: 0.4986 - val_accuracy: 0.9490\n",
            "Epoch 7/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.5067 - val_loss: 0.4988 - val_accuracy: 0.9490\n",
            "Epoch 8/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.5067 - val_loss: 0.4993 - val_accuracy: 0.9490\n",
            "Epoch 9/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.5067 - val_loss: 0.4998 - val_accuracy: 0.9490\n",
            "Epoch 10/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.5052 - accuracy: 0.5067 - val_loss: 0.5002 - val_accuracy: 0.9490\n",
            "Epoch 11/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5052 - accuracy: 0.5067 - val_loss: 0.5004 - val_accuracy: 0.9490\n",
            "Epoch 12/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5052 - accuracy: 0.5067 - val_loss: 0.5004 - val_accuracy: 0.9490\n",
            "Epoch 13/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5052 - accuracy: 0.5069 - val_loss: 0.5004 - val_accuracy: 0.9500\n",
            "Epoch 14/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5052 - accuracy: 0.5066 - val_loss: 0.5004 - val_accuracy: 0.9500\n",
            "Epoch 15/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.5052 - accuracy: 0.5065 - val_loss: 0.5004 - val_accuracy: 0.9450\n",
            "Epoch 16/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.5011 - val_loss: 0.5004 - val_accuracy: 0.9390\n",
            "Epoch 17/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.4958 - val_loss: 0.5004 - val_accuracy: 0.7910\n",
            "Epoch 18/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.4890 - val_loss: 0.5004 - val_accuracy: 0.9250\n",
            "Epoch 19/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.4911 - val_loss: 0.5004 - val_accuracy: 0.0840\n",
            "Epoch 20/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.5061 - val_loss: 0.5004 - val_accuracy: 0.1170\n",
            "Epoch 21/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.4988 - val_loss: 0.5004 - val_accuracy: 0.8870\n",
            "Epoch 22/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.5016 - val_loss: 0.5004 - val_accuracy: 0.9500\n",
            "Epoch 23/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.5075 - val_loss: 0.5004 - val_accuracy: 0.9260\n",
            "Epoch 24/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.5069 - val_loss: 0.5004 - val_accuracy: 0.9520\n",
            "Epoch 25/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.5121 - val_loss: 0.5004 - val_accuracy: 0.9500\n",
            "Epoch 26/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.5064 - val_loss: 0.5004 - val_accuracy: 0.9490\n",
            "Epoch 27/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.5073 - val_loss: 0.5003 - val_accuracy: 0.9490\n",
            "Epoch 28/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.5067 - val_loss: 0.4943 - val_accuracy: 0.9490\n",
            "Epoch 29/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.5020 - val_loss: 0.5004 - val_accuracy: 0.0500\n",
            "Epoch 30/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.5052 - accuracy: 0.4885 - val_loss: 0.5004 - val_accuracy: 0.0510\n",
            "Epoch 31/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.4890 - val_loss: 0.5004 - val_accuracy: 0.0520\n",
            "Epoch 32/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5052 - accuracy: 0.5015 - val_loss: 0.5004 - val_accuracy: 0.9490\n",
            "Epoch 33/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.5052 - accuracy: 0.4974 - val_loss: 0.4987 - val_accuracy: 0.9490\n",
            "Epoch 34/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.5052 - accuracy: 0.5067 - val_loss: 0.5004 - val_accuracy: 0.9490\n",
            "Epoch 35/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.5052 - accuracy: 0.5070 - val_loss: 0.5004 - val_accuracy: 0.9490\n",
            "Epoch 36/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5052 - accuracy: 0.5035 - val_loss: 0.5004 - val_accuracy: 0.9490\n",
            "Epoch 37/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.5052 - accuracy: 0.5065 - val_loss: 0.5004 - val_accuracy: 0.9490\n",
            "Epoch 38/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.5066 - val_loss: 0.5004 - val_accuracy: 0.9490\n",
            "Epoch 39/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.5064 - val_loss: 0.5004 - val_accuracy: 0.9490\n",
            "Epoch 40/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5051 - accuracy: 0.5095 - val_loss: 0.5004 - val_accuracy: 0.9490\n",
            "Epoch 41/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.4877 - val_loss: 0.5002 - val_accuracy: 0.9490\n",
            "Epoch 42/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5053 - accuracy: 0.5066 - val_loss: 0.5003 - val_accuracy: 0.9490\n",
            "Epoch 43/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.5067 - val_loss: 0.5000 - val_accuracy: 0.9490\n",
            "Epoch 44/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.5052 - val_loss: 0.5004 - val_accuracy: 0.9500\n",
            "Epoch 45/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.5050 - val_loss: 0.5004 - val_accuracy: 0.9490\n",
            "Epoch 46/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.5067 - val_loss: 0.5004 - val_accuracy: 0.9500\n",
            "Epoch 47/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.5039 - val_loss: 0.5004 - val_accuracy: 0.9520\n",
            "Epoch 48/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.4983 - val_loss: 0.5004 - val_accuracy: 0.9470\n",
            "Epoch 49/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.5011 - val_loss: 0.5004 - val_accuracy: 0.9520\n",
            "Epoch 50/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.5052 - accuracy: 0.5042 - val_loss: 0.5004 - val_accuracy: 0.9490\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define the test sets\n",
        "test_set_1 = np.array([[0.125, 0.25, 0.375, 0.25], [0.375, 0.25, 0.125, 0.25]])\n",
        "test_set_2 = np.array([[0.25, 0.125, 0.25, 0.375], [0.25, 0.375, 0.25, 0.125]])\n",
        "\n",
        "# Load the models\n",
        "model_standard = keras.models.load_model('/content/drive/MyDrive/Leakage Detection/Final_models/model_standard_1.h5')\n",
        "model_standard_aug = keras.models.load_model('/content/drive/MyDrive/Leakage Detection/Final_models/model_standard_2.h5')\n",
        "\n",
        "# load the saved weights\n",
        "model_equivariant = keras.models.load_model('/content/drive/MyDrive/Leakage Detection/Final_models/model_equivariant_3.h5')\n",
        "model_equivariant_aug = keras.models.load_model('/content/drive/MyDrive/Leakage Detection/Final_models/model_equivariant_4_augmented.h5')\n",
        "\n",
        "\n",
        "\n",
        "#model_equivariant_aug.load_weights('/content/drive/MyDrive/Leakage Detection/model_equivariant_4_augmented.h5')\n",
        "\n",
        "# Make predictions on the test sets\n",
        "pred_standard = model_standard.predict(test_set_1)\n",
        "pred_standard_aug = model_standard_aug.predict(test_set_1)\n",
        "pred_equivariant = model_equivariant.predict(test_set_1)\n",
        "pred_equivariant_aug = model_equivariant_aug.predict(test_set_1)\n",
        "\n",
        "# Plot the predictions\n",
        "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
        "fig.suptitle('Model predictions on test set 1')\n",
        "axs[0, 0].scatter(test_set_1[:, 0], test_set_1[:, 2])\n",
        "axs[0, 0].scatter(pred_standard[:, 0], pred_standard[:, 1])\n",
        "axs[0, 0].set_title('Standard model')\n",
        "axs[0, 1].scatter(test_set_1[:, 0], test_set_1[:, 2])\n",
        "axs[0, 1].scatter(pred_standard_aug[:, 0], pred_standard_aug[:, 1])\n",
        "axs[0, 1].set_title('Standard model with augmentation')\n",
        "axs[1, 0].scatter(test_set_1[:, 0], test_set_1[:, 2])\n",
        "axs[1, 0].scatter(pred_equivariant[:, 0], pred_equivariant[:, 1])\n",
        "axs[1, 0].set_title('Equivariant model')\n",
        "axs[1, 1].scatter(test_set_1[:, 0], test_set_1[:, 2])\n",
        "axs[1, 1].scatter(pred_equivariant_aug[:, 0], pred_equivariant_aug[:, 1])\n",
        "axs[1, 1].set_title('Equivariant model with augmentation')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "id": "HglsQ8Be0h9s",
        "outputId": "4736ed5a-6fd9-4894-b82c-fe3087fcd7d2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 108ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 4 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlkAAAKGCAYAAAB5kI69AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzde7wddX3v/9fbcIsoFyX1SLgEkVKDWOiJeM6vrVpFgXoEzu94wdZTsCrFSm1rS4UjVUq1Wmm99Ff6Q2xpvfwQ46Wc2GIjKqiUQyUIgoGmhosmAZU7KBET/Pz+mNk42eydvXayZ1/Wfj0fj/XYM/Od76zPzFrz3Z/1ne+alapCkiRJU+txMx2AJEnSMDLJkiRJ6oFJliRJUg9MsiRJknpgkiVJktQDkyxJkqQemGRJc0SSJUkqyQ4DrHtSkiumI64xnnuLOJN8LsmJ27Cd/ZL8IMmCqY9SkvpnkiX1IMltSX6cZK9Ry69tE5AlMxPZ9KuqY6rqwxOt1x6zIzv1vlNVT6iqR/qNsB+j92c7ttNbwty+F5++lfKnJlmR5Pb59r6VpoJJltSfW4FXjcwkORR4/MyFs20G6TnT0PoJ8C/A/5jpQKS5yCRL6s9Hgd/ozJ8IfKS7QpLdk3wkyZ1Jvp3kzCSPa8sWJPmLJHcluQV4yRh1/y7JHUk2JHnHIJfWOpfzTm57KO5I8oed8rOSfCrJx5I8AJy0tecaIM7Lk7yuM//6JDcleTDJjUl+IclHgf2Az7aXCP9ojMuOe7e9KvckWZvk9aNiXt4eyweTrE6yrFP+ljbuB5OsSfLCcY7N1l6Pk5Jc0e7rvUluTXLMONt5zP60y/9LkiuT3JfkG0me36lzUpJb2hhvTfLrSZ4BnAf813Y7943zfI+p2yn7zfZ435tkZZL92+VfaVf5RrvtV47eblV9r6r+Brh6rOeVNIGq8uHDxxQ/gNuAI4E1wDOABcB6YH+ggCXteh8B/jfwRGAJ8B/Aa9uyU4B/B/YFngRc1tbdoS3/R+CDwK7AzwBfA36rLTsJuGKc2Ja02/l4W/dQ4E7gyLb8LGATcDzNB7GFEzzXRHFeDryunX45sAF4NhDg6cD+3WM2Rpwj2/kK8DfALsBhbcwv6MT8I+BX22P9LuCqtuxgYB2wd2e7B45zbLb2epzUHpfXt8/xBuB2IFt7D3TmFwN3tzE+DnhRO7+oPa4PAAe36z4VOGSi17It31rd44C1NO/BHYAzgSs7dQt4+gDv5x3ovG99+PAx2MOeLKlfI71ZLwJuokkwgKYHCDgBOKOqHqyq24C/BP5nu8orgPdX1bqquocmcRip+xSaf9a/V1U/rKrvA+9rtzeoP2nr3gD8PZ1Lm8D/qaqLq+onwG4TPNe4cY7hdcB7qurqaqytqm9PFGiSfYFfBN5SVT+qquuAv2XLnsIrquqSasZwfRT4+Xb5I8DOwNIkO1bVbVV18xjPMdHrAfDtqvpQ+xwfpklonjJR/K1XA5e0Mf6kqi4FVtEcW2guzT0zycKquqOqVg+43a3VPQV4V1XdVFWbgT8DDhvpzZLUL5MsqV8fBX6NpjfiI6PK9gJ2BLpJxrdpejwA9qbpgemWjdi/rXtHe+npPpqepp+ZRGyjt733OGUTPdfW4hxtX+AxCc4A9gbuqaoHRz3P4s78dzvTDwG7JNmhqtYCv0fT2/X9JBcl6e7riIlejy2eo6oeaiefMOA+7A+8fOQYtsfxl4CnVtUPgVfSJEV3JPnnJD83yEYnqLs/8IHO891D04O4eOytSZpKJllSj9pemltpeis+M6r4LprLT91ehf34aW/XHTRJSbdsxDrgYWCvqtqjfexWVYdMIrzR2769G/oknmtrcY62DjhwnLIaZzltbE9K8sRRz7NhnPW33HDVhVX1S/z0cu2fj7HaRK/HZI3en3XARzvHcI+q2rWq3t3GuLKqXkTTO/bvwIfG2c5jn2j8uutoLut2n3NhVV25jfskaRJMsqT+vZZm7NAPuwvbS07LgXcmeWJ7CefNwMfaVZYDb0qyT5I9gdM7de8APg/8ZZLdkjwuyYFJnjeJuP44yeOTHAK8BvjEWCsN8FzjxjmGvwX+MMl/TuPpnUtX3wOeNk4M64ArgXcl2SXJs2iO68fGWr8rycFJXpBkZ5pxWxtpLq+Nfo6JXo/JGr0/HwNemuSoNF8W2CXJ89vj9pQkxyXZlSah/UEnxu8B+yTZaZz921rd84Az2td4ZGD/y7cS41jb34XmcivAzu28pAGYZEk9q6qbq2rVOMW/A/wQuAW4ArgQuKAt+xCwEvgG8HUe2xP2G8BOwI3AvcCnaHoyBvVlmkHRXwT+oqo+v5V1t/ZcE8X5qKr6JPBOmv18ELiYZrA8NGO5zmwvbf3hGNVfRTMY/Xaagfhvr6ovTLiXTYLwbpqequ/SXOY8Y5x1t/Z6TNYW+9MmiscB/4tm0P464DSadvhxNAnd7TSX9J5HM7Ae4EvAauC7Se4a43nGrVtV/0jTa3dRmm+KfhPofiPyLODDbYyvGGc/NtIkbtD0km2cxDGQ5rVUTdgTLWmIpLmh5K3Aju1gaElSD+zJkiRJ6oFJliRJUg+8XChJktQDe7IkSZJ6YJIlSZLUA5MsSZKkHphkSZIk9cAkS5IkqQcmWZIkST0wyZIkSeqBSZYkSVIPTLIkSZJ6YJIlSZLUA5MsSZKkHphkSZIk9cAkS5IkqQcmWZIkST0wyZIkSeqBSZYkSVIPTLIkSZJ6YJIlSZLUA5MsSZKkHphkSZIk9cAkS5IkqQcmWZIkST0wyZIkSeqBSZYkSVIPTLIkSZJ6YJIlSZLUA5MsSZKkHphkSZIk9cAkS5IkqQcmWZIkST0wyZIkSeqBSZYkSVIPTLIkSZJ6YJIlSZLUA5MsSZKkHphkSZIk9cAkS5IkqQcmWZIkST0wyZIkSeqBSZYkSVIPTLIkSZJ6YJIlSZLUA5MsTZkkz0+yfgq3d1KSK6Zqe5N87tuSHDnAekuSVJIdpiMuabp5Xm/X8/0gydO2Nx5tKcnqJM+f6TgGYZI1ZJL8UpIrk9yf5J4k/5rk2W3ZjDVukrad5/XcVFVPqKpbAJL8Q5J3zHRMM22yieVYx62qDqmqy6c8uB746XuIJNkN+CfgDcByYCfgl4GHZzKuQSTZoao2z3Qc0mzjeS3NXfZkDZefBaiqj1fVI1W1sao+X1XXJ3kGcB7wX9su7PsAkrwkybVJHkiyLslZIxvrdJmfmOQ7Se5K8tZO+cL2U8a9SW4Ent0NJsnpSW5O8mCSG5P8907ZSe2n8fcluRs4K8mTk6xoY/kacOB4O9qJ7TVt3PcmOSXJs5Ncn+S+JH/dWf9xSc5M8u0k30/ykSS7d8r/Z1t2d3cfO3VH9uXuJMuTPGmyL460jTyvZ9F53cb22c78t5J8sjO/Lslh7XQleXqSk4FfB/6ofZ0+29nkYe2+3Z/kE0l2Ged5D0zypTbWu5L8f0n26JRXkqd35rfoAUryR0nuSHJ7ktd112/X/Zskn2vj+9ck/ynJ+9vX4N+THN7Z1t5JPp3kziS3JnlTp+ys9lh+pH2PrE6yrC37KLAf8Nn2ef6oXf7JJN9tj8FXkhzSLh/zuKXTG5Zk5zbO29vH+5Ps3JY9P8n6JH/Qvj/uSPKaiV7jKVVVPobkAewG3A18GDgG2HNU+UnAFaOWPR84lCbhfhbwPeD4tmwJUMCHgIXAz9N8en5GW/5u4KvAk4B9gW8C6zvbfjmwd7vtVwI/BJ7aiWUz8Ds0PaoLgYtoPqnvCjwT2DA63s62R2I7D9gFeDHwI+Bi4GeAxcD3gee16/8msBZ4GvAE4DPAR9uypcAPgOcCOwPvbWM7si3/XeAqYJ+2/IPAx0fFscNMv/4+hvPheT27zuv2ue5r939v4Nsjx6ctuxd4XDtfwNPb6X8A3jFqW7cBX2u38yTgJuCUcY7N04EXtbEuAr4CvL9T/uhzjX4+4Gjgu8AhwOOBj40R213Af26P+5eAW4HfABYA7wAua9d9HHAN8DaaXtWnAbcAR7XlZ7Wv2a+2dd8FXDVqn48ctW+/CTyx3bf3A9eNtR9jbQM4u30df6Y9LlcCf9o5Dza36+zYxvQQo86hXs/fmW5AfEzxCwrPaN+U69s31wrgKW3ZSYzTuHXqvx94Xzu9pD0R9+mUfw04oZ2+BTi6U3YyncZ4jG1fBxzXieU7nbIFwCbg5zrL/my8eDuxLe4suxt4ZWf+08DvtdNfBH67U3Zw+3w7tI3FRZ2yXYEfd07im4AXdsqf2qk7EodJlo/eHp7Xs+u8BtYBvwCcAJzfHr+fA14DrOisN0iS9erO/HuA8wZ8TxwPXDvWc41+PuAC4F2dsqePEduHOuW/A9zUmT8UuK+dfk73NW6XnQH8fTt9FvCFTtlSYOOofT5yK/u1Rxvb7hMct5HX8WbgVztlRwG3tdPPBzZ2X0eaJP2/TNe56+XCIVNVN1XVSVW1D82nxr1pGtgxJXlOksvabt/7gVOAvUat9t3O9EM0nxhpt72uU/btUdv+jSTXtV3897XxdLfdrbuIpnEbd3vj+F5neuMY891Yu9v7dvt8Txm9H1X1Q5qGfcT+wD929uMm4JG2rtQ7z+tZd15/meYf+HPb6cuB57WPLw9Qv2u812ELSZ6S5KIkG5I8QNMbNfo1Hc/o13TdGOsMesz3B/YeOW7tsftfbHncRu/TLhnnm5pJFiR5d3vZ9gGaBAomt2+j3wN7d+bvri3HBY57jPtgkjXEqurfaT4FPHNk0RirXUjzqXjfqtqdpps+Az7FHTSXE0bsNzKRZH+ayxGnAk+uqj1oLjt0t92N506aT+hjbm8K3E7TOHS3vZmmIdliP5I8HnhyZ911wDFVtUfnsUtVbZjC+KSBeF5vYabO65Ek65fb6S8zcZI11us0GX/WbuPQqtoNeDVbHveHaC4FjvhPnek7aC6Ljui+HpO1Drh11HF7YlX96oD1Rx+HXwOOA44EdqfpRYSf7ttEx22s98DtA8bSO5OsIZLk59oBfvu08/sCr6K5Xg1Nw7NPkp061Z4I3FNVP0pyBM0bflDLgTOS7Nk+5+90ynalOTnubGN5DT/9p/AYVfUIzXiKs5I8PslS4MRJxDKRjwO/n+SAJE+gabA+0X7C+RTw39J8TX4nmuv33XPjPOCd7T8YkixKctwUxiaNy/N6q2bqvP4y8CvAwqpaTzOG7WiaJO7acep8j2b80rZ6Is0Ys/uTLAZOG1V+HfBrbc/Q0TQJ34jlwGuSPKNNNv94O+L4GvBgkrek+ZLEgiTPTHtLkQGMPg5PpBkTeDdNkvhnE6w/2seBM9vXby+ay8QfGzCW3plkDZcHaa6X/1uSH9I0wt8E/qAt/xKwGvhukrvaZb8NnJ3kQZo35/JJPN+f0HTN3gp8HvjoSEFV3Qj8JfB/aE6SQ4F/nWB7p9J0436X5pP6308ilolc0Mb3lTbeH9H+86iq1cAbaT7930EzcLV788UP0PQKfL49TlfRHGdpOnhej29Gzuuq+g+ahOer7fwDNGPZ/rVNLMfyd8DS9hLbxZPYxxF/QjMO7H7gn2mS167fBV5KMyj/12m+LDAS7+eAvwIuo/miwEiCPunbgLT799+Aw2iO+V3A39L0Qg3iXTRJ0X1J/hD4CM37bQNwYye2ERMdt3cAq4DrgRuAr7fLZoW0A8EkSdI8kObWH98Edi7vY9Yre7IkSRpySf57e0+pPYE/Bz5rgtU/kyxJkobfb9HcvuBmmm9RvmFmw5kfvFwoSZLUA3uyJEmSejDrfiB6r732qiVLlsx0GJKm0TXXXHNXVS2a6Timgm2YNL9srf2adUnWkiVLWLVq1UyHIWkaJRnkLuBzgm2YNL9srf3ycqEkSVIPTLIkSZJ6YJIlSZLUA5MsSZKkHphkSZIk9cAkS5IkqQez7hYOml4XX7uBc1au4fb7NrL3Hgs57aiDOf7wxTMdliTNONtHbS+TrHns4ms3cMZnbmDjpkcA2HDfRs74zA0ANiSS5jXbR00FLxfOY+esXPNoAzJi46ZHOGflmhmKSJJmB9tHTQWTrHns9vs2Tmq5JM0Xto+aCiZZ89jeeyyc1HJJmi9sHzUVTLLmsdOOOpiFOy7YYtnCHRdw2lEHz1BEkjQ72D5qKjjwfR4bGbzpt2ckaUu2j5oKJlnz3PGHL7bRkKQx2D5qe3m5UJIkqQcmWZIkST0wyZIkSeqBSZYkSVIPTLIkSZJ6YJIlSZLUA5MsSZKkHphkSZIk9cAkS5IkqQcmWZKGWpKjk6xJsjbJ6WOUn5LkhiTXJbkiydJ2+ZIkG9vl1yU5b/qjlzSX+bM6koZWkgXAucCLgPXA1UlWVNWNndUurKrz2vWPBd4LHN2W3VxVh01nzJKGhz1ZkobZEcDaqrqlqn4MXAQc112hqh7ozO4K1DTGJ2mImWRJGmaLgXWd+fXtsi0keWOSm4H3AG/qFB2Q5NokX07yy+M9SZKTk6xKsurOO++cqtglzXEmWZLmvao6t6oOBN4CnNkuvgPYr6oOB94MXJhkt3Hqn19Vy6pq2aJFi6YnaEmz3kBJlgNHJc1RG4B9O/P7tMvGcxFwPEBVPVxVd7fT1wA3Az/bU5yShtCESVZn4OgxwFLgVSNJVMeFVXVoO0D0PTQDR0fcXFWHtY9TpipwSRrA1cBBSQ5IshNwArCiu0KSgzqzLwG+1S5f1LZ/JHkacBBwy7RELWkoDPLtwkcHjgIkGRk4+ui3cxw4Kmk2qqrNSU4FVgILgAuqanWSs4FVVbUCODXJkcAm4F7gxLb6c4Gzk2wCfgKcUlX3TP9eSJqrBkmyxho4+pzRKyV5I824hZ2AF3SKDkhyLfAAcGZVfXWMuicDJwPst99+AwcvSROpqkuAS0Yte1tn+nfHqfdp4NP9RidpmE3ZwPftGTjqoFFJkjRsBkmyHDgqSZI0SYMkWQ4clSRJmqQJx2Q5cFSSJGnyBvrtQgeOSpIkTY53fJckSeqBSZYkSVIPTLIkSZJ6YJIlSZLUA5MsSZKkHphkSZIk9cAkS5IkqQcmWZIkST0wyZIkSeqBSZYkSVIPTLIkSZJ6MHeTrOuXw/ueCWft0fy9fvlMRyRJkvSogX4geta5fjl89k2waWMzf/+6Zh7gWa+YubgkSZJac7Mn64tn/zTBGrFpY7NckiRpFpibSdb96ye3XJIkaZrNzSRr930mt1ySJGmazc0k64Vvgx0Xbrlsx4XNckmSpFlgbiZZz3oFvPSvYPd9gTR/X/pXDnqXJEmzxtz8diE0CZVJlaQJJDka+ACwAPjbqnr3qPJTgDcCjwA/AE6uqhvbsjOA17Zlb6qqldMZu6S5bW72ZEnSAJIsAM4FjgGWAq9KsnTUahdW1aFVdRjwHuC9bd2lwAnAIcDRwN+025OkgZhkSRpmRwBrq+qWqvoxcBFwXHeFqnqgM7srUO30ccBFVfVwVd0KrG23J0kDmbuXCyVpYouBdZ359cBzRq+U5I3Am4GdgBd06l41qu7isZ4kycnAyQD77bffdgctaTjYkyVp3quqc6vqQOAtwJnbUP/8qlpWVcsWLVo09QFKmpNMsiQNsw3Avp35fdpl47kIOH4b60rSFkyyJA2zq4GDkhyQZCeagewruiskOagz+xLgW+30CuCEJDsnOQA4CPjaNMQsaUg4JkvS0KqqzUlOBVbS3MLhgqpaneRsYFVVrQBOTXIksAm4Fzixrbs6yXLgRmAz8MaqemRGdkTSnGSSJWmoVdUlwCWjlr2tM/27W6n7TuCd/UUnaZh5uVCSJKkHJlmSJEk9MMmSJEnqgUmWJElSD0yyJEmSemCSJUmS1AOTLEmSpB4MlGQlOTrJmiRrk5w+RvkpSW5Icl2SK5Is7ZSd0dZbk+SoqQxekiRptpowyUqyADgXOAZYCryqm0S1LqyqQ6vqMOA9wHvbuktpfsbiEOBo4G/a7UmSJA21QXqyjgDWVtUtVfVjmh9QPa67QlU90JndFah2+jjgoqp6uKpuBda225MkSRpqg/yszmJgXWd+PfCc0SsleSPwZmAn4AWduleNqrt4jLonAycD7LfffoPELUmSNKtN2cD3qjq3qg4E3gKcOcm651fVsqpatmjRoqkKSZIkacYMkmRtAPbtzO/TLhvPRcDx21hXkiRpKAySZF0NHJTkgCQ70QxkX9FdIclBndmXAN9qp1cAJyTZOckBwEHA17Y/bEmSpNltwjFZVbU5yanASmABcEFVrU5yNrCqqlYApyY5EtgE3Auc2NZdnWQ5cCOwGXhjVT3S075IkiTNGoMMfKeqLgEuGbXsbZ3p391K3XcC79zWACVJkuYi7/guSZLUA5MsSZKkHphkSZIk9cAkS5IkqQcmWZIkST0wyZIkSeqBSZYkSVIPTLIkSZJ6YJIlaaglOTrJmiRrk5w+Rvmbk9yY5PokX0yyf6fskSTXtY8Vo+tK0tYMdMd3SZqLkiwAzgVeBKwHrk6yoqpu7Kx2LbCsqh5K8gbgPcAr27KNVXXYtAYtaWjYkyVpmB0BrK2qW6rqx8BFwHHdFarqsqp6qJ29CthnmmOUNKRMsiQNs8XAus78+nbZeF4LfK4zv0uSVUmuSnL8eJWSnNyut+rOO+/cvoglDQ0vF0oSkOTVwDLgeZ3F+1fVhiRPA76U5Iaqunl03ao6HzgfYNmyZTUtAUua9ezJkjTMNgD7dub3aZdtIcmRwFuBY6vq4ZHlVbWh/XsLcDlweJ/BShouJlmShtnVwEFJDkiyE3ACsMW3BJMcDnyQJsH6fmf5nkl2bqf3An4R6A6Yl6St8nKhpKFVVZuTnAqsBBYAF1TV6iRnA6uqagVwDvAE4JNJAL5TVccCzwA+mOQnNB9I3z3qW4mStFUmWZKGWlVdAlwyatnbOtNHjlPvSuDQfqOTNMy8XChJktQDkyxJkqQemGRJkiT1wCRLkiSpByZZkiRJPTDJkiRJ6oFJliRJUg9MsiRJknpgkiVJktQDkyxJkqQemGRJkiT1wCRLkiSpByZZkiRJPTDJkiRJ6oFJliRJUg9MsiRJknowUJKV5Ogka5KsTXL6GOVvTnJjkuuTfDHJ/p2yR5Jc1z5WTGXwkiRJs9UOE62QZAFwLvAiYD1wdZIVVXVjZ7VrgWVV9VCSNwDvAV7Zlm2sqsOmOG5JkqRZbZCerCOAtVV1S1X9GLgIOK67QlVdVlUPtbNXAftMbZiSJElzyyBJ1mJgXWd+fbtsPK8FPteZ3yXJqiRXJTl+rApJTm7XWXXnnXcOEJIkSdLsNuHlwslI8mpgGfC8zuL9q2pDkqcBX0pyQ1Xd3K1XVecD5wMsW7aspjImSZKkmTBIT9YGYN/O/D7tsi0kORJ4K3BsVT08sryqNrR/bwEuBw7fjnglSZLmhEGSrKuBg5IckGQn4ARgi28JJjkc+CBNgvX9zvI9k+zcTu8F/CLQHTAvSZI0lCZMsqpqM3AqsBK4CVheVauTnJ3k2Ha1c4AnAJ8cdauGZwCrknwDuAx496hvJUpSr7bzFjQnJvlW+zhxeiOXNNcNNCarqi4BLhm17G2d6SPHqXclcOj2BChJ22p7bkGT5EnA22nGmRZwTVv33undC0lzlXd8lzTMtucWNEcBl1bVPW1idSlw9DTFLWkImGRJGmbbcwuaget6GxpJYzHJkiS2uAXNOZOtW1XnV9Wyqlq2aNGiqQ9O0pxkkiVpmG3PLWgGqitJ4zHJkjTMtvkWNDTfqH5xeyuaPYEXt8skaSBTesd3SZpNqmpzkpFb0CwALhi5BQ2wqqpWsOUtaAC+U1XHVtU9Sf6UJlEDOLuq7pmB3ZA0R5lkSRpq23oLmrbsAuCC/qKTNMy8XChJktQDkyxJkqQemGRJkiT1wCRLkiSpByZZkiRJPTDJkiRJ6oFJliRJUg9MsiRJknpgkiVJktQDkyxJkqQemGRJkiT1wCRLkiSpByZZkiRJPTDJkiRJ6oFJliRJUg9MsiRJknpgkiVJktQDkyxJkqQemGRJkiT1wCRLkiSpByZZkiRJPTDJkiRJ6oFJliRJUg9MsiRJknpgkiVpqCU5OsmaJGuTnD5G+XOTfD3J5iQvG1X2SJLr2seK6Yta0jDYYaYDkKS+JFkAnAu8CFgPXJ1kRVXd2FntO8BJwB+OsYmNVXVY74FKGkomWZKG2RHA2qq6BSDJRcBxwKNJVlXd1pb9ZCYClDS8BrpcOEB3+5uT3Jjk+iRfTLJ/p+zEJN9qHydOZfCSNIHFwLrO/Pp22aB2SbIqyVVJjh9vpSQnt+utuvPOO7c1VklDZsIkq9PdfgywFHhVkqWjVrsWWFZVzwI+Bbynrfsk4O3Ac2g+Ub49yZ5TF74k9Wr/qloG/Brw/iQHjrVSVZ1fVcuqatmiRYumN0JJs9YgPVmPdrdX1Y+Bke72R1XVZVX1UDt7FbBPO30UcGlV3VNV9wKXAkdPTeiSNKENwL6d+X3aZQOpqg3t31uAy4HDpzI4ScNtkCRrst3trwU+N5m6drVL6snVwEFJDkiyE3ACMNC3BJPsmWTndnov4BfpjOWSpIlM6S0ckrwaWAacM5l6drVL6kNVbQZOBVYCNwHLq2p1krOTHAuQ5NlJ1gMvBz6YZHVb/RnAqiTfAC4D3j3qW4mStFWDfLtwoO72JEcCbwWeV1UPd+o+f1Tdy7clUEnaFlV1CXDJqGVv60xfzU+HOHTXuRI4tPcAJQ2tQXqyJuxuT3I48EHg2Kr6fqdoJfDittt9T+DF7TJJkqShNmFPVlVtTjLS3b4AuGCkux1YVVUraC4PPgH4ZBKA71TVsVV1T5I/pUnUAM6uqnt62RNJkqRZZKCbkQ7Q3X7kVupeAFywrQFKkiTNRf52oSRJUg9MsiRJknpgkiVJktQDkyxJkqQeDDTwXZIkadhdfO0Gzlm5htvv28jeeyzktKMO5vjDJ/Ob8lsyyZIkSfPexddu4IzP3MDGTY8AsOG+jZzxmRsAtjnR8nKhJEma985ZuebRBGvExk2PcM7KNdu8TZMsSZI0791+38ZJLR+ESZYkSZr39t5j4aSWD8IkS5IkzXunHXUwC3dcsMWyhTsu4LSjDt7mbTrwXZIkzXsjg9v9dqEkSdIUO3O9zp0AACAASURBVP7wxduVVI3m5UJJkqQemGRJkiT1wCRLkiSpByZZkiRJPTDJkiRJ6oFJliRJUg9MsiRJknpgkiVJktQDkyxJkqQemGRJGmpJjk6yJsnaJKePUf7cJF9PsjnJy0aVnZjkW+3jxOmLWtIwMMmSNLSSLADOBY4BlgKvSrJ01GrfAU4CLhxV90nA24HnAEcAb0+yZ98xSxoeJlmShtkRwNqquqWqfgxcBBzXXaGqbquq64GfjKp7FHBpVd1TVfcClwJHT0fQkoaDSZakYbYYWNeZX98um9K6SU5OsirJqjvvvHObApU0fEyyJGk7VdX5VbWsqpYtWrRopsORNEuYZEkaZhuAfTvz+7TL+q4rSSZZkoba1cBBSQ5IshNwArBiwLorgRcn2bMd8P7idpkkDcQkS9LQqqrNwKk0ydFNwPKqWp3k7CTHAiR5dpL1wMuBDyZZ3da9B/hTmkTtauDsdpkkDWSHmQ5AkvpUVZcAl4xa9rbO9NU0lwLHqnsBcEGvAUoaWvZkSZIk9cAkS5IkqQcmWZIkST0wyZIkSerBQEnWdv7A6iNJrmsfg351WpIkaU6b8NuFnR9YfRHNz0pcnWRFVd3YWW3kB1b/cIxNbKyqw6YgVkmSpDljkFs4PPoDqwBJRn5g9dEkq6pua8tG/8CqJEnSvDTI5cLt+YFVgF3aH069KsnxY63gj6tKkqRhMx0D3/evqmXArwHvT3Lg6BX8cVVJkjRsBkmytutHUqtqQ/v3FuBy4PBJxCdJkjQnDZJkbfMPrLY/rLpzO70X8It0xnJJkiQNqwmTrO35gVXgGcCqJN8ALgPePepbiZIkSUNpoB+I3tYfWK2qK4FDtzNGSZKkOcc7vkuSJPXAJEuSJKkHJlmSJEk9MMmSJEnqgUmWJElSD0yyJEmSemCSJUnT7frl8L5nwll7NH+vXz7TEUnqwUD3yZIkTZHrl8Nn3wSbNjbz969r5gGe9YqZi0vSlLMnS5Km0xfP/mmCNWLTxma5pKFikiVJ0+n+9ZNbLmnOMsmSNNSSHJ1kTZK1SU4fo3znJJ9oy/8tyZJ2+ZIkG5Nc1z7Om5KAdn/ML5BtfbmkOcskS9LQSrIAOBc4BlgKvCrJ0lGrvRa4t6qeDrwP+PNO2c1VdVj7OGVKgnrh22DHhVsu23Fhs1zSUHHgu6QpdfG1Gzhn5Rpuv28je++xkNOOOpjjD188U+EcAaytqlsAklwEHAfc2FnnOOCsdvpTwF8nSW8RjQxu/+LZzSXC3fdpEiwHvUtDxyRL0pS5+NoNnPGZG9i46REANty3kTM+cwPATCVai4F1nfn1wHPGW6eqNie5H3hyW3ZAkmuBB4Azq+qrYz1JkpOBkwH222+/iaN61itMqqR5wMuFkqbMOSvXPJpgjdi46RHOWblmhiLaLncA+1XV4cCbgQuT7DbWilV1flUtq6plixYtmtYgJc1eJlmSpszt922c1PJpsAHYtzO/T7tszHWS7ADsDtxdVQ9X1d0AVXUNcDPws71HLGlomGRJmjJ777FwUsunwdXAQUkOSLITcAKwYtQ6K4AT2+mXAV+qqkqyqB04T5KnAQcBt0xT3JKGgEmWpClz2lEHs3DHBVssW7jjAk476uAZiaeqNgOnAiuBm4DlVbU6ydlJjm1X+zvgyUnW0lwWHLnNw3OB65NcRzMg/pSqumd690DSXObAd0lTZmRw+yz6diFVdQlwyahlb+tM/wh4+Rj1Pg18uvcAJQ0tkyxJU+r4wxfPaFIlSbOFlwslSZJ6YJIlSZLUA5MsSZKkHphkSSOuXw7veyactUfz9/rlMx2RNDw8vzQPOfBdgqbB/+ybYFN708z71zXz4M+fSNvL80vzlD1ZEjQ/1rtp1F3JN21slkvaPp5fmqdMsiSA+9dPbrmkwXl+aZ4yyZIAdt9ncsslDc7zS/OUSZYE8MK3wY6jfl9vx4XNcknbx/NL85RJlgTN4NuX/hXsvi+Q5u9L/8pBudJU8PzSPOW3C6URz3qFjb7UF88vzUP2ZEmSJPXAJEuSJKkHJlmSJEk9GCjJSnJ0kjVJ1iY5fYzy5yb5epLNSV42quzEJN9qHydOVeCSJEmz2YRJVpIFwLnAMcBS4FVJlo5a7TvAScCFo+o+CXg78BzgCODtSfbc/rAlSZJmt0F6so4A1lbVLVX1Y+Ai4LjuClV1W1VdD/xkVN2jgEur6p6quhe4FDh6CuKWJEma1Qa5hcNiYF1nfj1Nz9Qgxqq7ePRKSU4GTm5nf5BkzYDbH8RewF1TuL3ZbD7tK8yv/R32fd1/pgOYKtdcc81dSb49avGwvH7ux+zifswO47Zfs+I+WVV1PnB+H9tOsqqqlvWx7dlmPu0rzK/9nU/7OtdV1aLRy4bl9XM/Zhf3Y/Yb5HLhBmDfzvw+7bJBbE9dSZKkOWuQJOtq4KAkByTZCTgBWDHg9lcCL06yZzvg/cXtMkmSpKE2YZJVVZuBU2mSo5uA5VW1OsnZSY4FSPLsJOuBlwMfTLK6rXsP8Kc0idrVwNntsunUy2XIWWo+7SvMr/2dT/s6jIbl9XM/Zhf3Y5ZLVc10DJIkSUPHO75LkiT1wCRLkiSpB0OTZA3w0z87J/lEW/5vSZZMf5RTY3t+5miuGWBf35zkxiTXJ/likjl9v6UB9veUJDckuS7JFWP8+oJmgSRPSnJp+3Nil473SxdJ/iXJfUn+abpj3JphaU+Hoa0cljZw3rZtVTXnH8AC4GbgacBOwDeApaPW+W3gvHb6BOATMx13j/u6BHgW8BHgZTMdc8/7+ivA49vpN8zV13US+7tbZ/pY4F9mOm4fY76W7wFOb6dPB/58nPVeCLwU+KeZjrkT01C0p8PQVg5LGzif27Zh6cma8Kd/2vkPt9OfAl6YJNMY41TZnp85mmsG2dfLquqhdvYqmnuxzVWD7O8DndldAb+5Mjt125sPA8ePtVJVfRF4cLqCGtCwtKfD0FYOSxs4b9u2YUmyBvn5nkfXqea2FPcDT56W6KbWQD9VNCQmu6+vBT7Xa0T9GvRnqN6Y5Gaa3pI3TVNsmpynVNUd7fR3gafMZDCTNCzt6TC0lcPSBs7btm1YkizNc0leDSwDzpnpWPpWVedW1YHAW4AzZzqe+SrJF5J8c4zH6E/oxZB8KtfsNQxt4DC2bbPitwunwCA/3zOyzvokOwC7A3dPT3hTaj79VNFA+5rkSOCtwPOq6uFpiq0Pk31tLwL+314j0riq6sjxypJ8L8lTq+qOJE8Fvj+NoW2vYWlPh6GtHJY2cN62bcPSkzXIT/+sAE5sp18GfKn9hDnXbM/PHM01E+5rksOBDwLHVtVc+kc2lkH296DO7EuAb01jfBpct705EfjfMxjLZA1LezoMbeWwtIHzt22b6ZH3U/UAfhX4D5pvMLy1XXY2zRsPYBfgk8Ba4GvA02Y65h739dk017x/SPPpcvVMx9zjvn4B+B5wXftYMdMx97y/HwBWt/t6GXDITMfsY8zX8cnAF2n+UXwBeFK7fBnwt531vgrcCWxsz9mjZjr2Nq6haE+Hoa0cljZwvrZt/qyOJElSD4blcqEkSdKsYpIlSZLUA5MsSZKkHphkSZIk9cAkS5IkqQcmWZIkST0wyZIkSeqBSZYkSVIPTLIkSZJ6YJIlSZLUA5MsSZKkHphkSZIk9cAkS5IkqQcmWZIkST0wyZIkSeqBSZYkSVIPTLIkSZJ6YJIlSZLUA5MsPSrJfkl+kGTBXNr2dEtyeZLXDbhuJXl63zFJY/GcHsx0n9NJVid5/lTEo59K8rkkJ850HF0mWXNQktuSbGwbuJHHX2/vdqvqO1X1hKp6ZCri7GvbSf4hyTumIi5pNvCcnl/ndFUdUlWXAyQ5K8nHZjikGTfZxHKs41ZVx1TVh6c+um23w0wHoG320qr6wkwHMYgkO1TV5pmOQ5rlPKelIWNP1pBJsiDJXyS5K8ktSd7Ydm/v0JbfluTIzvqPfhpIsmRk3SSvTLJq1LZ/P8mKdvolSa5N8kCSdUnO6qw3sp3XJvkO8KXuttt1XpPkpiQPtnH+Vqf+85OsT/IHSb6f5I4kr2nLTgZ+Hfij9tP+Z8c5DpXkt5N8q32OP01yYJIr25iXJ9mps/7rk6xNck+SFUn27pS9KMm/J7m/7V3IqOf6zXZf7k2yMsn+k3zZpHF5Tj+6jVl9Tif5lSQ3dOYvTXJ1Z/6rSY7vvmZJjgb+F/DKdt+/0dnk/kn+td3XzyfZa5zn3TPJPyW5s433n5Ls0ykf9/3Rzv9Gkm8nuTvJH3fXb9f9ZJKPtXHckORnk5zRvo7rkry4s63dk/xd+/puSPKOtJeTk5yU5Ir2vXxvkluTHNOWvRP4ZeCv0+nFTfKB9jkeSHJNkl9ul4953NLpDUvyuCRntvv2/SQfSbJ7Wzby3j0xyXfSnFtvneg13iZV5WOOPYDbgCPHKTsF+HdgX+BJwGVAATuMVRc4C/hYO71kZF3g8cCDwEGdda8GTminnw8cSpOoPwv4HnD8qO18BNgVWNjddrvOS4ADaRq35wEPAb/Q2fZm4GxgR+BX2/I92/J/AN4xwTEq4H8DuwGHAA8DXwSeBuwO3Aic2K77AuAu4BeAnYH/B/hKW7ZXexxe1sby+21sr2vLjwPWAs9oj9uZwJWj4nj6TL9nfMzuh+f03D+n22Pyo3b7O7bHbwPwxLZsI/Dk0a9Z9/XqbOty4GbgZ9u6lwPvHue4PBn4H+3r+0Tgk8DF47232PL9sRT4AfBLwE7AXwCbRsX2I+Co9lh8BLgVeGu7j68Hbu1s+x+BD7bvkZ8Bvgb8Vlt2Urvt1wMLgDcAtwPp7PPrRu3bq9v92wH4A+C7wC4THLeR1/E329fxacATgM8AHx31fv5Qe3x/nub99IypPrftyZq7Lk5yX+fx+nb5K4D3V9W6qroHeNe2bLyqHqJp0F4FkOQg4OeAFW355VV1Q1X9pKquBz5O07B2nVVVP6yqjWNs/5+r6uZqfBn4PM0nmRGbgLOralNVXULTEBw8yd14T1U9UFWrgW8Cn6+qW6rqfuBzwOHter8OXFBVX6+qh4EzgP+aZAnNP4PVVfWpqtoEvJ/mRB9xCvCuqrqpmssnfwYcNsgnX2kUz+mJzdpzuj0mVwPPBf4z8A3gX4FfBP4L8K2qunsS+/r3VfUf7XaXA4eN87x3V9Wnq+qhqnoQeCePfd3G8zLgs1V1RVX9GHgbTfLR9dWqWtkei08Ci2gSvk3ARcCSJHskeQrNsf299j3yfeB9wAmdbX27qj5UzTi+DwNPBZ4yXnBV9bF2/zZX1V/SJMyDvmd+HXhv+/74Ac174IS0Pa+tP6mqjVX1DZrX6+cH3PbATLLmruOrao/O40Pt8r2BdZ31vr0dz3EhbYMM/BrNp6OHAJI8J8llbRf1/TQN0+ju7HWMI8kxSa5qu/Lvozk5u/Xvri3HfDxE82lkMr7Xmd44xvzI9vamc5zaE/JuYDGjjmc1H4O6+7U/8IGRf4zAPTSf5BdPMlbJc3pis/2c/jJNr91z2+nLaRKe57Xzk9FN/MY9Vkken+SD7WWxB4CvAHtksG99jj4WD9Ecp67Rx/iu+umXHUaS7SfQHLcdgTs6x+6DND1aj9mnkffdePvV7tsfprlse3+7vd157Htya/vWPVe+TdMj1k3qBjrG28Mka/jcQXNZYcR+o8p/SNOtPOI/bWVblwKLkhxG0zBf2Cm7kOYT8L5VtTtwHqPGNfDYT0QAJNkZ+DRN1/RTqmoP4JIx6o9nzO1uh9tpGoiR+Hal6aLewKjjmSRseXzX0XSHd/85LqyqK6c4Rs1fntOTN1Pn9Ogk68tMnGRt777/AU3vznOqarf2ueGnx35r7487gO74rYU0x2lbrKO55LZX57jtVlWHDFh/i+PQjr/6I5qe3D3b99T9/HS/JjpuW7wHaM6bzWyZNPbOJGv4LAfelGSfJHsCp48qv46my3THJMtouovH1HYHfxI4h2YsyKWd4icC91TVj5IcQfOpeFA70XT73glsbgc/vnjrVbbwPZrr7FPl48BrkhzW/rP4M+Dfquo24J+BQ5L8320385vYspE6DzgjySHw6MDPl09hbJLn9OTN1Dl9JU3CcwTwtfay5v7Ac2h6mMbyPZpLbtv6//iJND1K9yV5EvD2UeVbe398Cnhpkv8rzZcGzmLwxHgLVXUHzSXiv0yyWzvw/MAkg166HP0eeCJNUnQnsEOSt9GMx+uuv7Xj9nHg95MckOQJNO+BT9Q0fyvWJGvu+my2vKfOP7bLPwSspLm+/HWawX5df0wzOPVe4E/Y8pPsWC4EjgQ+OerN+dvA2UkepLmOv3zQwNtxA29q69xL05ivGLQ+8HfA0rZL+uJJ1Bsvni/QHJdP03yyO5B2HEFV3QW8HHg3TTf6QTTjLEbq/iPw58BFbVf9N4FjtjcmzUue03P8nK6qH9K8RqvbMU4A/4dmLNL3x6n2yfbv3Um+Pug+dryfZvD2XcBVwL+MKh/3/dEmgb9DM7bqDppxct+n6ZHaFr9Bk3Df2D7fp2jGXQ3iA8DL0nzz8K9o3vP/AvwHzaW+H7HlZd2JjtsFwEdpkttb2/q/M6m9mQIjo/o1pNqBnrcCO053Bi9p6nlOqy9tj899NN9AvXWm4xkG9mRJkjRPJXlpO3h+V5oxdTfQ3PZBU8AkS5Kk+es4mkHit9NcOj2hvMQ1ZbxcKEmS1AN7siRJknow634geq+99qolS5bMdBiSptE111xzV1Utmuk4poJtmDS/bK39mnVJ1pIlS1i1atXEK0oaGkm25y7ms4ptmDS/bK398nKhJElSD0yyJEmSemCSJUmS1AOTLEmSpB6YZEmSJPXAJEuSJKkHs+4WDhouF1+7gXNWruH2+zay9x4LOe2ogzn+8MUzHZYkTcj2S9vLJEu9ufjaDZzxmRvYuOkRADbct5EzPnMDgA2VpFnN9ktTwcuF6s05K9c82kCN2LjpEc5ZuWaGIpKkwdh+aSqYZKk3t9+3cVLLJWm2sP3SVDDJUm/23mPhpJZL0mxh+6WpYJKl3px21MEs3HHBFssW7riA0446eIYikqTB2H5pKjjwXb0ZGRzqt3MkzTW2X5oKJlnq1fGHL7ZRkjQn2X5pe3m5UJIkqQcmWZIkST0wyZIkSeqBSZYkSVIPTLIkSZJ6YJIlSZLUA5MsSZKkHphkSZIk9WCgJCvJ0UnWJFmb5PQxyk9JckOS65JckWRpu3xJko3t8uuSnDfVOyBJW2P7JWmmTHjH9yQLgHOBFwHrgauTrKiqGzurXVhV57XrHwu8Fzi6Lbu5qg6b2rAlaWK2X5Jm0iA9WUcAa6vqlqr6MXARcFx3hap6oDO7K1BTF6IkbTPbL0kzZpAkazGwrjO/vl22hSRvTHIz8B7gTZ2iA5Jcm+TLSX55rCdIcnKSVUlW3XnnnZMIX5K2qvf2q61vGybpMaZs4HtVnVtVBwJvAc5sF98B7FdVhwNvBi5MstsYdc+vqmVVtWzRokVTFZIkDWR72q+2vm2YpMcYJMnaAOzbmd+nXTaei4DjAarq4aq6u52+BrgZ+NltC1WSJs32S9KMGSTJuho4KMkBSXYCTgBWdFdIclBn9iXAt9rli9qBpyR5GnAQcMtUBC5JA7D9kjRjJvx2YVVtTnIqsBJYAFxQVauTnA2sqqoVwKlJjgQ2AfcCJ7bVnwucnWQT8BPglKq6p48dkaTRbL8kzaRUza4v0ixbtqxWrVo102FImkZJrqmqZTMdx1SwDZPml621X97xXZIkqQcmWZIkST0wyZIkSeqBSZYkSVIPTLIkSZJ6YJIlSZLUA5MsSZKkHphkSZIk9cAkS5IkqQcmWZIkST0wyZIkSeqBSZYkSVIPTLIkSZJ6YJIlSZLUA5MsSZKkHphkSZIk9cAkS5IkqQcmWZIkST0wyZIkSeqBSZYkSVIPTLIkSZJ6YJIlSZLUA5MsSZKkHphkSZIk9WCgJCvJ0UnWJFmb5PQxyk9JckOS65JckWRpp+yMtt6aJEdNZfCSNBHbL0kzZcIkK8kC4FzgGGAp8KpuI9S6sKoOrarDgPcA723rLgVOAA4Bjgb+pt2eJPXO9kvSTBqkJ+sIYG1V3VJVPwYuAo7rrlBVD3RmdwWqnT4OuKiqHq6qW4G17fYkaTrYfkmaMTsMsM5iYF1nfj3wnNErJXkj8GZgJ+AFnbpXjaq7eIy6JwMnA+y3336DxC1Jg+i9/Wrr24ZJeowpG/heVedW1YHAW4AzJ1n3/KpaVlXLFi1aNFUhSdJAtqf9auvbhkl6jEGSrA3Avp35fdpl47kIOH4b60rSVLL9kjRjBkmyrgYOSnJAkp1oBoKu6K6Q5KDO7EuAb7XTK4ATkuyc5ADgIOBr2x+2JA3E9kvSjJlwTFZVbU5yKrASWABcUFWrk5wNrKqqFcCpSY4ENgH3Aie2dVcnWQ7cCGwG3lhVj/S0L5K0BdsvSTMpVTXxWtNo2bJltWrVqpkOQ9I0SnJNVS2b6Timgm2YNL9srf3yju+SJEk9MMmSJEnqgUmWJElSD0yyJEmSemCSJUmS1AOTLEmSpB6YZEmSJPXAJEuSJKkHJlmSJEk9MMmSJEnqgUmWJElSD0yyJEmSemCSJUmS1AOTLEmSpB6YZEmSJPXAJEuSJKkHJlmSJEk9MMmSJEnqgUmWJElSD0yyJEmSemCSJUmS1AOTLEmSpB6YZEmSJPVgoCQrydFJ1iRZm+T0McrfnOTG/P/t3X+s3XV9x/HnKy1gNyM/tHFKy6+tM3aG2ORY/zDBLCDgFgp/IENjggkJ0Y34h5kJBiOm/qPyhxsJmZDNxC0xWI1x1UQbREzcH7heBEuK6SiNo61OOxFcRgMU3vvjftHTu1vu97bnc7/n9D4fyck938/3e8r7ww2vvjjne9tkT5IHklw4du6lJI92j52THF6SlmJ+SRrK2qUuSLIGuBt4D3AI2J1kZ1U9PnbZI8Coqp5L8hHg88BfdeeOVtXbJzy3JC3J/JI0pD7vZG0F9lfVgap6AbgPuHb8gqp6sKqe6w4fAjZMdkxJOinml6TB9ClZ5wMHx44PdWsncjPwnbHj1ySZS/JQkusWe0GSW7pr5o4cOdJjJEnqpXl+gRkmaXFLfly4HEk+CIyAd48tX1hVh5NcAnw/yWNV9eT466rqXuBegNFoVJOcSZL6ONn8AjNM0uL6vJN1GNg4dryhWztOkiuA24FtVfX8K+tVdbj7egD4AbDlFOaVpOUwvyQNpk/J2g1sSnJxkjOBG4HjfsomyRbgHuYD6ldj6+cmOat7/gbgXcD4DaeS1JL5JWkwS35cWFXHktwK7ALWAF+qqr1JtgNzVbUTuBN4LfC1JABPVdU24K3APUleZr7QfXbBT/VIUjPml6QhpWq6bh8YjUY1Nzc39BiSVlCSh6tqNPQck2CGSavLq+WXf+K7JElSA5YsSZKkBixZkiRJDViyJEmSGrBkSZIkNWDJkiRJasCSJUmS1IAlS5IkqQFLliRJUgOWLEmSpAYsWZIkSQ1YsiRJkhqwZEmSJDVgyZIkSWrAkiVJktSAJUuSJKkBS5YkSVIDlixJkqQGLFmSJEkNWLIkSZIasGRJkiQ1YMmSJElqwJIlSZLUgCVLkiSpgV4lK8nVSfYl2Z/ktkXOfyzJ40n2JHkgyYVj525K8kT3uGmSw0vSUswvSUNZsmQlWQPcDbwX2Ay8P8nmBZc9Aoyq6lLg68Dnu9eeB9wBvBPYCtyR5NzJjS9JJ2Z+SRpSn3eytgL7q+pAVb0A3AdcO35BVT1YVc91hw8BG7rnVwH3V9XTVfUb4H7g6smMLklLMr8kDaZPyTofODh2fKhbO5Gbge8s57VJbkkyl2TuyJEjPUaSpF6a5xeYYZIWN9Eb35N8EBgBdy7ndVV1b1WNqmq0fv36SY4kSb2cbH6BGSZpcX1K1mFg49jxhm7tOEmuAG4HtlXV88t5rSQ1Yn5JGkyfkrUb2JTk4iRnAjcCO8cvSLIFuIf5gPrV2KldwJVJzu1uGL2yW5OklWB+SRrM2qUuqKpjSW5lPlzWAF+qqr1JtgNzVbWT+bfXXwt8LQnAU1W1raqeTvIZ5oMOYHtVPd1kJ5K0gPklaUipqqFnOM5oNKq5ubmhx5C0gpI8XFWjoeeYBDNMWl1eLb/8E98lSZIasGRJkiQ1YMmSJElqwJIlSZLUgCVLkiSpAUuWJElSA5YsSZKkBixZkiRJDViyJEmSGrBkSZIkNWDJkiRJasCSJUmS1IAlS5IkqQFLliRJUgOWLEmSpAYsWZIkSQ1YsiRJkhqwZEmSJDVgyZIkSWrAkiVJktSAJUuSJKkBS5YkSVIDlixJkqQGLFmSJEkN9CpZSa5Osi/J/iS3LXL+siQ/TnIsyfULzr2U5NHusXNSg0tSH+aXpKGsXeqCJGuAu4H3AIeA3Ul2VtXjY5c9BXwI+NtFfomjVfX2CcwqSctifkka0pIlC9gK7K+qAwBJ7gOuBX4XUlX1s+7cyw1mlKSTZX5JGkyfjwvPBw6OHR/q1vp6TZK5JA8luW6xC5Lc0l0zd+TIkWX80pL0qprnF5hhkha3Eje+X1hVI+ADwN8l+eOFF1TVvVU1qqrR+vXrV2AkSeplyfwCM0zS4vqUrMPAxrHjDd1aL1V1uPt6APgBsGUZ80nSqTC/JA2mT8naDWxKcnGSM4EbgV4/ZZPk3CRndc/fALyLsXshJKkx80vSYJYsWVV1DLgV2AX8FNhRVXuTbE+yDSDJO5IcAt4H3JNkb/fytwJzSX4CPAh8dsFP9UhSM+aXpCGlqoae4Tij0ajm5uaGHkPSCkrycHfv08wzw6TV5dXyyz/xXZIkqQFLliRJUgOWLEmSpAYsWZIkSQ1YsiRJkhqwZEmSJDVgyZIkSWpg7dADSDq9fPORw9y5ax8/f+Yobz5nHR+/6i1ct2U5fyezJA1jn8R8vgAACXtJREFU0vllyZI0Md985DCf+MZjHH3xJQAOP3OUT3zjMQCLlqSp1iK//LhQ0sTcuWvf7wLqFUdffIk7d+0baCJJ6qdFflmyJE3Mz585uqx1SZoWLfLLkiVpYt58zrplrUvStGiRX5YsSRPz8avewroz1hy3tu6MNXz8qrcMNJEk9dMiv7zxXdLEvHJzqD9dKGnWtMgvS5akibpuy/mWKkkzadL55ceFkiRJDViyJEmSGrBkSZIkNWDJkiRJasCSJUmS1IAlS5IkqQFLliRJUgOWLEmSpAZ6lawkVyfZl2R/ktsWOX9Zkh8nOZbk+gXnbkryRPe4aVKDS1If5pekoSxZspKsAe4G3gtsBt6fZPOCy54CPgR8ZcFrzwPuAN4JbAXuSHLuqY8tSUszvyQNqc87WVuB/VV1oKpeAO4Drh2/oKp+VlV7gJcXvPYq4P6qerqqfgPcD1w9gbklqQ/zS9Jg+pSs84GDY8eHurU+er02yS1J5pLMHTlypOcvLUlLap5fYIZJWtxU3PheVfdW1aiqRuvXrx96HElaFjNM0mL6lKzDwMax4w3dWh+n8lpJOlXml6TB9ClZu4FNSS5OciZwI7Cz56+/C7gyybndDaNXdmuStBLML0mDWbJkVdUx4Fbmw+WnwI6q2ptke5JtAEnekeQQ8D7gniR7u9c+DXyG+aDbDWzv1iSpOfNL0pBSVUPPcJzRaFRzc3NDjyFpBSV5uKpGQ88xCWaYtLq8Wn5NxY3vkiRJpxtLliRJUgOWLEmSpAYsWZIkSQ1YsiRJkhqwZEmSJDVgyZIkSWrAkiVJktSAJUuSJKkBS5YkSVIDlixJkqQGLFmSJEkNWLIkSZIasGRJkiQ1YMmSJElqwJIlSZLUgCVLkiSpAUuWJElSA5YsSZKkBixZkiRJDcxuydqzA77wNvj0OfNf9+wYeiJJ6sf8klaFtUMPcFL27IBvfRRePDp//OzB+WOAS28Ybi5JWor5Ja0as/lO1gPbfx9Qr3jx6Py6JE0z80taNWazZD17aHnrkjQtzC9p1ehVspJcnWRfkv1Jblvk/FlJvtqd/1GSi7r1i5IcTfJo9/jiRKY+e8Py1iWtWuaXpKEsWbKSrAHuBt4LbAben2TzgstuBn5TVX8CfAH43Ni5J6vq7d3jwxOZ+vJPwRnrjl87Y938uiR1zC9JQ+rzTtZWYH9VHaiqF4D7gGsXXHMt8OXu+deBy5NkcmMucOkNcM1dcPZGIPNfr7nLm0YlLWR+SRpMn58uPB84OHZ8CHjnia6pqmNJngVe3527OMkjwG+BT1bVDxf+A5LcAtwCcMEFF/Sb/NIbDCVJS2meX3ASGWZ+SatC6xvffwFcUFVbgI8BX0nyuoUXVdW9VTWqqtH69esbjyRJvfTKLzDDJC2uT8k6DGwcO97QrS16TZK1wNnAr6vq+ar6NUBVPQw8CfzpqQ4tST2ZX5IG06dk7QY2Jbk4yZnAjcDOBdfsBG7qnl8PfL+qKsn67sZTklwCbAIOTGZ0SVqS+SVpMEvek9Xdo3ArsAtYA3ypqvYm2Q7MVdVO4J+Af0myH3ia+SADuAzYnuRF4GXgw1X1dIuNSNJC5pekIaWqhp7hOKPRqObm5oYeQ9IKSvJwVY2GnmMSzDBpdXm1/JrNP/FdkiRpylmyJEmSGrBkSZIkNWDJkiRJasCSNUv27IAvvA0+fc781z07hp5Ikvoxv7QK9flrdTQN9uyAb30UXjw6f/zswflj8K/nkDTdzC+tUr6TNSse2P77gHrFi0fn1yVpmplfWqUsWbPi2UPLW5ekaWF+aZWyZM2Kszcsb12SpoX5pVXKkjUrLv8UnLHu+LUz1s2vS9I0M7+0SlmyZsWlN8A1d8HZG4HMf73mLm8alTT9zC+tUv504Sy59AZDSdJsMr+0CvlOliRJUgOWLEmSpAYsWZIkSQ1YsiRJkhqwZEmSJDVgyZIkSWogVTX0DMdJcgT4z0VOvQH47xUep4XTYR+nwx7AfUyTC6tq/dBDTMIJMux0+B6B+5g27mM6nDC/pq5knUiSuaoaDT3HqTod9nE67AHch1bO6fI9ch/TxX1MPz8ulCRJasCSJUmS1MAslax7hx5gQk6HfZwOewD3oZVzunyP3Md0cR9TbmbuyZIkSZols/ROliRJ0sywZEmSJDUwtSUryXlJ7k/yRPf13BNc990kzyT59krPeCJJrk6yL8n+JLctcv6sJF/tzv8oyUUrP+XSeuzjsiQ/TnIsyfVDzNhHj318LMnjSfYkeSDJhUPMuZQe+/hwkseSPJrk35JsHmJOzXZ+gRk2TcyvGVdVU/kAPg/c1j2/DfjcCa67HLgG+PbQM3fzrAGeBC4BzgR+AmxecM1fA1/snt8IfHXouU9yHxcBlwL/DFw/9MynsI8/B/6ge/6RGf5+vG7s+Tbgu0PPvVofs5pf3Uxm2JQ8zK/hZz/Vx9S+kwVcC3y5e/5l4LrFLqqqB4D/WamhetgK7K+qA1X1AnAf83sZN763rwOXJ8kKztjHkvuoqp9V1R7g5SEG7KnPPh6sque6w4eADSs8Yx999vHbscM/BPypluHMan6BGTZNzK8ZN80l641V9Yvu+X8BbxxymGU4Hzg4dnyoW1v0mqo6BjwLvH5Fpuuvzz5mwXL3cTPwnaYTnZxe+0jyN0meZP6dlI+u0Gz6/2Y1v8AMmybm14xbO+Q/PMn3gD9a5NTt4wdVVUlOi1ar6ZXkg8AIePfQs5ysqrobuDvJB4BPAjcNPNJpy/zSNDG/ptOgJauqrjjRuSS/TPKmqvpFkjcBv1rB0U7FYWDj2PGGbm2xaw4lWQucDfx6Zcbrrc8+ZkGvfSS5gvnfHN9dVc+v0GzLsdzvx33APzSdaJU7TfMLzLBpYn7NuGn+uHAnv2+xNwH/OuAsy7Eb2JTk4iRnMn9T6M4F14zv7Xrg+9Xd7TdF+uxjFiy5jyRbgHuAbVU1rb8Z9tnHprHDvwSeWMH5dLxZzS8ww6aJ+TXrhr7z/kQP5j/ff4D5f9HfA87r1kfAP45d90PgCHCU+c95r5qC2f8C+A/mf5ri9m5tO/P/EQC8BvgasB/4d+CSoWc+yX28o/t3/r/M/1/s3qFnPsl9fA/4JfBo99g59MwnuY+/B/Z2e3gQ+LOhZ16tj1nOr24uM2xKHubXbD/8a3UkSZIamOaPCyVJkmaWJUuSJKkBS5YkSVIDlixJkqQGLFmSJEkNWLIkSZIasGRJkiQ18H+exL3iSgRi5gAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CrXPa8_C0iA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9s4OoptO0iIW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}